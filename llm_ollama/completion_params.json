{
    "model": "llama3",
    "parameters": {
        "temperature": 0.7,
        "top_p": 0.9,
        "num_ctx": 4096,
        "stop": ["</s>", "<|user|>", "/s>", "</s"]
    }
}